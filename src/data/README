Please find the description of the contents of this "data" directory below !

---------
Python Scripts
---------

mergeDuplicates.py
	+There are 73844 rows in halfDB.pkl, out of the number of unique school's are 61277. 
	+Hence there are repeated records because the school medium differs.
	+This script removes all duplicate rows with same school codes and replaces the 'Medium' column's value with list of all mediums associated with the respective school code.

unify_pkls.py
	+This script unifies all the pickles given in a folder into one pickle file. (Assumes the given folder contains a pickle named DISTRICTS, which is a pickle of a list of all file names in the given folder.)

process_xlsx.py
	+Reads all the excel sheets in scraped_xlsx
	+filters & normalises them
	+concatinates them to allScraped.pkl
	+finds intersection of new data with halfDB.pkl and adds this intersection to oneKB.pkl



-------
Pickle Files
-------

halfDF.pkl
	+ Pickle file of a dataframe consisting of all records from excel sheet given by Praveen Sir
	+Unified 'excelDB_pkls' folder

allScraped.pkl
	+Pickle file of a dataframe consisting of all records from excel sheet which was scraped from udise website.
	+Unified 'scraped_xlsx' folder

errors.pkl
	+Dataframe of all school which have to be manually checked because, there is some discrepancy in them.

oneKB.pkl
	+Pickle of a dataframe consisting of all error free records from both halfDB.pkl and allScraped.pkl
	+updated everytime new records are added into allScraped.pkl


-----
Folders
-----
excelDB_pkls:
	+All pickles of dataframes, one per district, extracted from the excel sheet given by Praveen Sir
	+One pickle file named 'DISTRICTS' which is a list of all districts from which school's records are present in the excel sheet

processed_xlsx:
	+Excel sheets which are already cleaned and concatenated to allScraped.pkl

scraped_xlsx:
	+Raw scraped data in form of excel sheets

